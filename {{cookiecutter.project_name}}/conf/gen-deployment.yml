f: !() # noqa
  workflows:
    - name: !? ("{0}-{{cookiecutter.workflow_name}}").format($.env)
      tags:
        env: !? $.env
        project: "my-project"
        pipeline: "{{cookiecutter.workflow_name}}"
        area: "analytics"

      !if $.env = 'prod':
        email_notifications:
          on_start: ["{{cookiecutter.author_email}}"]
          on_success: ["{{cookiecutter.author_email}}"]
          on_failure:
            - "{{cookiecutter.author_email}}"
        schedule:
          quartz_cron_expression: "20 0 7 ? * Tue"
          timezone_id: "America/Santiago"
          pause_status: "UNPAUSED"

      job_clusters:
        - job_cluster_key: !? $.env
          new_cluster:
            spark_version: "11.3.x-cpu-ml-scala2.12"
            policy_id: "cluster-policy://Job Compute"
            driver_node_type_id: "Standard_F8"
            node_type_id: "Standard_F8"
            !if $.env = 'prod':
              autoscale:
                min_workers: 2
                max_workers: 15
            !if $.env = 'dev':
              num_workers: 2
            !if $.env = 'staging':
              num_workers: 1

      tasks:
        - task_key: "sample-task"
          job_cluster_key: !? $.env
          python_wheel_task:
              package_name: "{{cookiecutter.package_name}}"
              entry_point: "sample_task"
              named_parameters:
                conf-file: "file:fuse://conf/tasks/sample_task_config.yml"
                env: !? $.env
build:
  python: "poetry"

environments:
  dev: !? ($_.f)({ env => 'dev' })
  prod: !? ($_.f)({ env => 'prod' })
  staging: !? ($_.f)({ env => 'staging' })
